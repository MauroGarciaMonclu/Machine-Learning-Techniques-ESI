{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WbBIQCD3gG_Q",
    "outputId": "e6602456-3a56-4a71-ea45-71808b6e7735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24518, 18)\n",
      "(4086, 18)\n"
     ]
    }
   ],
   "source": [
    "# 1 Filtering\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read T2\n",
    "df=pd.read_csv(\"task3_dataset.csv\")\n",
    "\n",
    "# list the columns\n",
    "list(df)\n",
    "\n",
    "# print number of rows and columns \n",
    "print (df.shape)\n",
    "\n",
    "# 1.1 Filter rows\n",
    "# convert string to datetime\n",
    "df['TimeStemp'] = pd.to_datetime(df['TimeStemp'])\n",
    "\n",
    "#Eliminar filas con valores nulos\n",
    "df.dropna()\n",
    "\n",
    "#filter data by date\n",
    "dfMondays = df[((df['TimeStemp'] > '2016-05-02 00:00:00') & (df['TimeStemp'] <= '2016-05-02 23:59:59')) | ((df['TimeStemp'] > '2016-05-9 00:00:00') & (df['TimeStemp'] <= '2016-05-9 23:59:59')) | ((df['TimeStemp'] > '2016-05-16 00:00:00') & (df['TimeStemp'] <= '2016-05-16 23:59:59'))]\n",
    "\n",
    "# print number of rows and columns\n",
    "print (dfMondays.shape)\n",
    "\n",
    "# save data base\n",
    "dfMondays.to_csv(\"T3_Mondays.csv\", index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s02QWPfXgQBv"
   },
   "outputs": [],
   "source": [
    "#Catch training and test values from the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#featuredColumns = ['GyroscopeStat_x_MEAN','MagneticField_x_MEAN','LinearAcceleration_x_MEAN','MagneticField_COV_z_x']\n",
    "featuredColumns = ['GyroscopeStat_x_MEAN']\n",
    "#featuredColumns = ['Pressure_MEAN']\n",
    "#featuredColumns = ['MagneticField_COV_z_x']\n",
    "\n",
    "#HERE START NAIVE BAYES LEARNER\n",
    "X = dfMondays[featuredColumns]\n",
    "Y = dfMondays[['attack']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6x-tetnhTUa"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Normalize the data\n",
    "escaler=StandardScaler()\n",
    "X_train=escaler.fit_transform(X_train)\n",
    "X_test=escaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxLP2gMjh64a"
   },
   "outputs": [],
   "source": [
    "#Define the algorithm to use\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "algoritm=LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "Z4ljyMP4iY5o",
    "outputId": "6a87ac7d-9486-4704-89fc-e259b35594e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "algoritm.fit(X_train,Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCL96VeYimEt"
   },
   "outputs": [],
   "source": [
    "#Prediction\n",
    "Y_pred_naive_bayes = algoritm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "oomzM1AEi7Nv",
    "outputId": "d97fecb3-3857-4d7a-963d-caadd0e9ccd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion:\n",
      "[[817   0]\n",
      " [  1   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Confusion matrix\n",
    "matrix = confusion_matrix(Y_test,Y_pred_naive_bayes)\n",
    "print(\"Matriz de confusion:\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "05TFqb1tjxSy",
    "outputId": "ba49ac91-a0f6-45e3-8a86-bbdb2ed9c80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del modelo:\n",
      "0.9987775061124695\n"
     ]
    }
   ],
   "source": [
    "#Precision of the algorithm\n",
    "from sklearn.metrics import precision_score \n",
    "\n",
    "precision = precision_score(Y_test, Y_pred_naive_bayes, average='weighted', labels= pd.unique(Y_pred_naive_bayes))\n",
    "print(\"Precision del modelo:\")\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE START DECISION TREE LEARNER\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "#Convert the dataframe from pandas to sql\n",
    "dfMondays = sqlCtx.createDataFrame(dfMondays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3289, 797)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#Merge selected columns into one\n",
    "assembler = VectorAssembler(inputCols = featuredColumns, outputCol=\"features\")\n",
    "assembled = assembler.transform(dfMondays)\n",
    "\n",
    "#Catch train and test data from chosen columns\n",
    "(trainingData, testData) = assembled.randomSplit([0.8,0.2], seed=123123) \n",
    "\n",
    "trainingData.count(), testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "#Start decision tree clasificator \n",
    "dt = DecisionTreeClassifier(labelCol=\"attack\", featuresCol=\"features\", maxDepth=5, minInstancesPerNode=20, impurity=\"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#Normalize data\n",
    "pipeline = Pipeline(stages=[dt])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions from the model\n",
    "\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "#Convert the attack column from int to double to prevent subsequent failure\n",
    "predictions = predictions.withColumn(\"attack\", predictions[\"attack\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction|attack|\n",
      "+----------+------+\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "|       0.0|   0.0|\n",
      "+----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compare first 10 rows (not necesary)\n",
    "predictions = predictions.select(\"prediction\",\"attack\")\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#Show success percentage of the model with the test data\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"attack\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "metrics = MulticlassMetrics(predictions.rdd.map(tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[797.]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion matrix from the decision tree\n",
    "metrics.confusionMatrix().toArray().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Naive Bayes Martes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
