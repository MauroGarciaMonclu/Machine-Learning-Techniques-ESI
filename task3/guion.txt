First of all we need to convert the pandas dataframe type used in the previous naive bayes learner, to sql context dataframe type because is necesary to use the pyspark functions that we will need to implement in the random tree.

Next we set the assembler with the featured columns also used in the naive bayes
Test split of 0.8 aleatory elements from the featured columns to train the model and 0.2 aleatory elements to test it.

Configuration of the decision tree classifier, we must specify the target data and the featured data in order to train the model that will be the same as those used previously in the naive bayes.

We have tried changing several values of the configuration and the variance in the precision of the results has been minimal

Until this stage we have only implemented naive bayes and a decision tree, but the roadmap is to get Y predictions of these mentioned learners, prove and check final accuracy with Bootstrap aggregating and Ada Boosting
